# -*- coding: utf-8 -*-
import os
import sys
import hashlib
from pathlib import Path
import streamlit as st

# =========================================================
# 1. sqlite3 í˜¸í™˜ (Chroma ì˜¤ë¥˜ ë°©ì§€)
# =========================================================
try:
    __import__("pysqlite3")
    sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")
except Exception:
    pass

# =========================================================
# 2. LangChain / Chroma
# =========================================================
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory
from langchain_chroma import Chroma

# =========================================================
# 3. API KEY
# =========================================================
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# =========================================================
# 4. Streamlit UI ê¸°ë³¸
# =========================================================
st.set_page_config(page_title="PDF RAG ì±—ë´‡", page_icon="ğŸ“š")
st.header("ğŸ“š PDF ê¸°ë°˜ RAG ì±—ë´‡")

# =========================================================
# 5. ìºì‹œ í•¨ìˆ˜
# =========================================================
@st.cache_resource(show_spinner=False)
def load_pdf(path):
    return PyPDFLoader(path).load()

@st.cache_resource(show_spinner=False)
def build_or_load_vectorstore(docs, persist_dir):
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    if os.path.isdir(persist_dir) and any(os.scandir(persist_dir)):
        return Chroma(
            persist_directory=persist_dir,
            embedding_function=embeddings
        )

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150
    )
    split_docs = splitter.split_documents(docs)

    return Chroma.from_documents(
        split_docs,
        embeddings,
        persist_directory=persist_dir
    )

# =========================================================
# 6. ëª¨ë¸ ì„ íƒ
# =========================================================
model_name = st.selectbox(
    "GPT ëª¨ë¸ ì„ íƒ",
    ("gpt-4o-mini", "gpt-3.5-turbo-0125")
)

# =========================================================
# 7. PDF ì—…ë¡œë“œ
# =========================================================
uploaded = st.file_uploader("ğŸ“„ PDF ì—…ë¡œë“œ", type=["pdf"])

pdf_path = None
persist_dir = None

if uploaded:
    tmp_dir = Path(".streamlit_tmp")
    tmp_dir.mkdir(parents=True, exist_ok=True)

    data = uploaded.getvalue()
    file_id = hashlib.sha256(data).hexdigest()[:12]

    pdf_path = tmp_dir / uploaded.name
    pdf_path.write_bytes(data)

    persist_dir = f"./chroma_db/{file_id}"
    st.success("PDF ì—…ë¡œë“œ ì™„ë£Œ")

if not pdf_path:
    st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ì§ˆë¬¸ ì…ë ¥ì°½ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
    st.stop()

# =========================================================
# 8. PDF â†’ ë²¡í„° DB
# =========================================================
pages = load_pdf(str(pdf_path))
vectorstore = build_or_load_vectorstore(pages, persist_dir)
retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

# =========================================================
# 9. RAG ì²´ì¸
# =========================================================
contextualize_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•´ ë…ë¦½ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ë¼."),
        MessagesPlaceholder("history"),
        ("human", "{input}")
    ]
)

qa_prompt = ChatPromptTemplate.from_messages(
    [
        ("system",
         "ë„ˆëŠ” ë°˜ë“œì‹œ PDFì—ì„œ ê²€ìƒ‰ëœ ë‚´ìš©(context)ë§Œìœ¼ë¡œ ë‹µí•´ì•¼ í•œë‹¤.\n"
         "contextì— ê·¼ê±°ê°€ ì—†ìœ¼ë©´ 'PDFì—ì„œ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ë‹µí•˜ë¼.\n\n"
         "{context}"
        ),
        MessagesPlaceholder("history"),
        ("human", "{input}")
    ]
)

llm = ChatOpenAI(model=model_name)

history_aware_retriever = create_history_aware_retriever(
    llm, retriever, contextualize_prompt
)

qa_chain = create_stuff_documents_chain(llm, qa_prompt)
rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)

chat_history = StreamlitChatMessageHistory(key="chat_messages")

conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    lambda session_id: chat_history,
    input_messages_key="input",
    history_messages_key="history",
    output_messages_key="answer",
)

# =========================================================
# 10. ì±„íŒ… UI (ì§ˆë¬¸ ì…ë ¥ì°½ âœ”)
# =========================================================
for msg in chat_history.messages:
    st.chat_message(msg.type).write(msg.content)

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.chat_message("human").write(prompt)

    with st.chat_message("ai"):
        with st.spinner("Thinking..."):
            config = {"configurable": {"session_id": "any"}}
            response = conversational_rag_chain.invoke(
                {"input": prompt},
                config
            )

            st.write(response.get("answer", ""))

            # ===============================
            # ğŸ” ë””ë²„ê·¸ íŒ¨ë„
            # ===============================
            with st.expander("ğŸ” RAG ë””ë²„ê·¸"):
                ctx = response.get("context", [])
                st.write("ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜:", len(ctx))
                st.write("PDF ê²½ë¡œ:", pdf_path)
                st.write("DB ê²½ë¡œ:", persist_dir)

                for i, doc in enumerate(ctx, 1):
                    st.markdown(f"### ë¬¸ì„œ {i}")
                    st.code(doc.page_content[:400])
