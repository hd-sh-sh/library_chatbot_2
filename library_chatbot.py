# -*- coding: utf-8 -*-
import os
import sys
import hashlib
from pathlib import Path
import streamlit as st

# =====================================================
# 1. sqlite3 í˜¸í™˜ (Chromaìš©)
# =====================================================
try:
    __import__("pysqlite3")
    sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")
except Exception:
    pass

# =====================================================
# 2. LangChain / Chroma
# =====================================================
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory

# =====================================================
# 3. API KEY
# =====================================================
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# =====================================================
# 4. Streamlit ê¸°ë³¸ ì„¤ì •
# =====================================================
st.set_page_config(page_title="PDF RAG ì±—ë´‡", page_icon="ğŸ“š")
st.title("ğŸ“š PDF ê¸°ë°˜ RAG ì±—ë´‡ (ë””ë²„ê·¸ í¬í•¨)")

# =====================================================
# 5. ìºì‹œ í•¨ìˆ˜
# =====================================================
@st.cache_resource(show_spinner=False)
def load_pdf(file_path):
    loader = PyPDFLoader(file_path)
    return loader.load()

@st.cache_resource(show_spinner=False)
def build_vectorstore(docs, persist_dir):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150
    )
    split_docs = splitter.split_documents(docs)

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    return Chroma.from_documents(
        split_docs,
        embeddings,
        persist_directory=persist_dir
    )

@st.cache_resource(show_spinner=False)
def load_or_create_vectorstore(docs, persist_dir):
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    if os.path.isdir(persist_dir) and any(os.scandir(persist_dir)):
        return Chroma(
            persist_directory=persist_dir,
            embedding_function=embeddings
        )

    return build_vectorstore(docs, persist_dir)

# =====================================================
# 6. PDF ì—…ë¡œë“œ
# =====================================================
uploaded = st.file_uploader("ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

pdf_path = None
file_id = None
persist_dir = None

if uploaded:
    tmp_dir = Path(".streamlit_tmp")
    tmp_dir.mkdir(parents=True, exist_ok=True)

    data = uploaded.getvalue()
    file_id = hashlib.sha256(data).hexdigest()[:12]

    pdf_path = str(tmp_dir / uploaded.name)
    with open(pdf_path, "wb") as f:
        f.write(data)

    persist_dir = f"./chroma_db/{file_id}"

    st.success("PDF ì—…ë¡œë“œ ì™„ë£Œ")

# =====================================================
# 7. PDF ì—†ìœ¼ë©´ ì¤‘ë‹¨
# =====================================================
if not pdf_path:
    st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

# =====================================================
# 8. PDF ë¡œë“œ + ë²¡í„° DB
# =====================================================
pages = load_pdf(pdf_path)

vectorstore = load_or_create_vectorstore(pages, persist_dir)
retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

# =====================================================
# 9. RAG ì²´ì¸
# =====================================================
contextualize_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•´ ë…ë¦½ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”."),
        MessagesPlaceholder("history"),
        ("human", "{input}")
    ]
)

qa_prompt = ChatPromptTemplate.from_messages(
    [
        ("system",
         "ë„ˆëŠ” PDFì—ì„œ ê²€ìƒ‰ëœ ë‚´ìš©(context)ë§Œìœ¼ë¡œ ë‹µí•´ì•¼ í•œë‹¤.\n"
         "contextì— ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ë°˜ë“œì‹œ 'PDFì—ì„œ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•´ë¼.\n\n"
         "{context}"
        ),
        MessagesPlaceholder("history"),
        ("human", "{input}")
    ]
)

llm = ChatOpenAI(model="gpt-4o-mini")

history_aware_retriever = create_history_aware_retriever(
    llm, retriever, contextualize_prompt
)

qa_chain = create_stuff_documents_chain(llm, qa_prompt)

rag_chain = create_retrieval_chain(
    history_aware_retriever,
    qa_chain
)

chat_history = StreamlitChatMessageHistory(key="chat_messages")

conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    lambda session_id: chat_history,
    input_messages_key="input",
    history_messages_key="history",
    output_messages_key="answer",
)

# =====================================================
# 10. ì±„íŒ… UI
# =====================================================
for msg in chat_history.messages:
    st.chat_message(msg.type).write(msg.content)

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.chat_message("human").write(prompt)

    with st.chat_message("ai"):
        with st.spinner("Thinking..."):
            config = {"configurable": {"session_id": "any"}}
            response = conversational_rag_chain.invoke(
                {"input": prompt},
                config
            )

            st.write(response.get("answer", ""))

            # ===============================
            # ğŸ” ë””ë²„ê·¸ íŒ¨ë„
            # ===============================
            with st.expander("ğŸ” RAG ë””ë²„ê·¸"):
                ctx = response.get("context", [])
                st.write("ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜:", len(ctx))
                st.write("pdf_path:", pdf_path)
                st.write("persist_directory:", persist_dir)

                for i, doc in enumerate(ctx, 1):
                    st.markdown(f"### ë¬¸ì„œ {i}")
                    st.code(doc.page_content[:400])
