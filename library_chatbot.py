# -*- coding: utf-8 -*-
import os
import sys
import shutil
import streamlit as st
from pathlib import Path

# =========================================================
# sqlite3 í˜¸í™˜ (Chroma ì•ˆì •í™”)
# =========================================================
try:
    __import__("pysqlite3")
    sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")
except Exception:
    pass

# =========================================================
# LangChain
# =========================================================
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory
from langchain_chroma import Chroma

# =========================================================
# OpenAI API KEY
# =========================================================
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# =========================================================
# Streamlit UI
# =========================================================
st.set_page_config(page_title="PDF ì¶”ê°€í•™ìŠµ RAG ì±—ë´‡", page_icon="ğŸ“š")
st.header("ğŸ“š PDF ì¶”ê°€ í•™ìŠµ RAG ì±—ë´‡")

# =========================================================
# ì‚¬ì´ë“œë°”: í•™ìŠµ ë°©ì‹
# =========================================================
mode = st.sidebar.radio(
    "ğŸ“˜ PDF í•™ìŠµ ë°©ì‹",
    ("ì¶”ê°€ í•™ìŠµ (ëˆ„ì )", "ìƒˆë¡œ í•™ìŠµ (ê¸°ì¡´ ì´ˆê¸°í™”)")
)

if mode == "ìƒˆë¡œ í•™ìŠµ (ê¸°ì¡´ ì´ˆê¸°í™”)":
    if st.sidebar.button("ğŸ§¹ ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ì‚­ì œ"):
        if os.path.exists("./chroma_db"):
            shutil.rmtree("./chroma_db")
        st.sidebar.success("ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

# =========================================================
# PDF ì—…ë¡œë“œ
# =========================================================
uploaded = st.file_uploader("ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

if not uploaded:
    st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ì§ˆë¬¸ ì…ë ¥ì°½ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
    st.stop()

tmp_dir = Path(".streamlit_tmp")
tmp_dir.mkdir(parents=True, exist_ok=True)

pdf_path = tmp_dir / uploaded.name
pdf_path.write_bytes(uploaded.getbuffer())

# =========================================================
# PDF ë¡œë“œ
# =========================================================
pages = PyPDFLoader(str(pdf_path)).load()

# =========================================================
# VectorStore (ì¶”ê°€ í•™ìŠµ í•µì‹¬)
# =========================================================
persist_dir = "./chroma_db"
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=150
)
split_docs = splitter.split_documents(pages)

if os.path.isdir(persist_dir) and any(os.scandir(persist_dir)):
    vectorstore = Chroma(
        persist_directory=persist_dir,
        embedding_function=embeddings
    )
    vectorstore.add_documents(split_docs)   # âœ… ì¶”ê°€ í•™ìŠµ
else:
    vectorstore = Chroma.from_documents(
        split_docs,
        embeddings,
        persist_directory=persist_dir
    )

retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

# =========================================================
# RAG Chain
# =========================================================
contextualize_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•´ ë…ë¦½ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ë¼."),
        MessagesPlaceholder("history"),
        ("human", "{input}")
    ]
)

qa_system_prompt = (
    "ë„ˆëŠ” PDF ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ë„ìš°ë¯¸ì´ë‹¤.\n"
    "ë°˜ë“œì‹œ ì•„ë˜ ë¬¸ì„œ ë‚´ìš©(context)ì— ê·¼ê±°í•´ì„œë§Œ ë‹µë³€í•´ì•¼ í•œë‹¤.\n"
    "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ê±°ë‚˜ ê·¼ê±°ê°€ ì—†ìœ¼ë©´\n"
    "ë°˜ë“œì‹œ 'í•´ë‹¹ ë‚´ìš©ì€ ì œê³µëœ PDF ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•˜ë¼.\n"
    "ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µí•˜ì§€ ë§ˆë¼.\n"
    "ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•˜ê³ , ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë¼.\n\n"
    "{context}"
)

qa_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", qa_system_prompt),
        MessagesPlaceholder("history"),
        ("human", "{input}")
    ]
)

llm = ChatOpenAI(model="gpt-4o-mini")

history_aware_retriever = create_history_aware_retriever(
    llm, retriever, contextualize_prompt
)

qa_chain = create_stuff_documents_chain(llm, qa_prompt)
rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)

chat_history = StreamlitChatMessageHistory(key="chat_messages")

conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    lambda session_id: chat_history,
    input_messages_key="input",
    history_messages_key="history",
    output_messages_key="answer"
)

# =========================================================
# ì±„íŒ… UI
# =========================================================
for msg in chat_history.messages:
    st.chat_message(msg.type).write(msg.content)

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.chat_message("human").write(prompt)

    with st.chat_message("ai"):
        with st.spinner("Thinking..."):
            response = conversational_rag_chain.invoke(
                {"input": prompt},
                {"configurable": {"session_id": "any"}}
            )

            st.write(response.get("answer", ""))

            with st.expander("ğŸ“„ ì°¸ê³  ë¬¸ì„œ"):
                for doc in response.get("context", []):
                    st.markdown(
                        doc.metadata.get("source", "source"),
                        help=doc.page_content
                    )
